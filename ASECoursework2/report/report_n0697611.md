% Advanced Software Engineering Functional Test-driven Development Report
% Daniel Holland N0697611

\pagebreak

# Test Driven Development

## Explanation of what TDD is

Test Driven Development is an approach to software development in which automated Unit Tests are written before code is, and then code is written to pass the new Unit Tests (Beck, K., 2003). Once this has been done, the code is refactored to remove duplication, and all tests are re-run to check that no regressions have occurred (Beck, K., 2003).

Test Driven Development thus gives programming the following structure (Beck, K., 2003):

1. Write a small test that does not pass
2. Make the test pass
3. Refactor the code, eliminating any duplication in the process


## Critical Evaluation of TDD


My own impression of Test Driven Development is that it is likely to be more useful the larger the program, and particularly when the program is maintained by many different developers (or even organisations). One issue from my own experience in industry however, is the if not appropriately named, structured, and commented, Unit Tests may be removed by future developers if they fail.  They are particularly likely to do this if they are not able to quickly discern the purpose of the test, and if they see no obvious symptoms. This defeats the objective of the original test writing. As such this is a process which requires not just discipline, but that it becomes a habit. The usage of this method in an organisation therefore requires that it becomes thoroughly inculcated in the organisation and its culture.

Another issue with Unit Tests I encountered in industry was that for a code base which contains many impure elements, a large amount of time is spent mocking the behaviour of impure elements, such as Data Access Objects, so that test data can be generated for the pure functions to be tested. With certain types of application, such as a CRUD Web Service, this is going to be a larger issue than with others, such as implementations of sorting and searching algorithms.


Maximilien, E.M. and Williams, L. (2003) details how IBM reduced their defect rate by 50% by using Test Driven Development as opposed to an ad-hos unit testing approach. However, whilst George, B. and Williams, L. (2004) also found TDD produced code that was of a higher quality (it passed 18% more functional black-box test cases), it is admitted that the code also took 16% longer to write. George, B. and Williams, L. (2004) also suggests that "waterfall-like approaches do not encourage adequate testing", testing not being core to the process, but rather being an afterthought. From this George, B. and Williams, L. (2004) suggests that increased usage of Test Driven Development would increase usage of Unit Testing generally. 


\pagebreak
# Using TDD

To try out Test Driven Development, I partially developmed a program intended to find the shortest path between two nodes in a network. The network was to be generated at pseudo-random.

The network must consist of Nodes, which must haven directional weighted Edges to other Nodes. 
To find the shortest path, a Genetic Algorithm was to be used.

This has the following process:

1. Generate pseudo-random Paths, made of selections of Edges from the Network 
2. Score the paths, for:
  1. Whether Start at the first Node
  2. Whether they End at the second
  3. Their total Weight
3. If not at the final generation, generate new Paths as follows, then return to step 2:
  1. Take the top ranking Paths, and to fill the whole of a new set with duplicates of these
  2. Add mutations to these by randomly adding and removing edges
  3. Mate these by taking pairs of Paths, slicing the Paths at random positions and fusing the paths back together 
4. Return the best scoring path




QuickCheck

In order to test the function `removeHeavierDuplicates` with a wider range of test data, the QuickCheck testing library was used. 

As the function takes a list of Edges as a parameter, `Edge` needed an instance declaration of `Arbitrary`. This allows QuickCheck to generate arbitrary Edges.

One of the properties of `removeHeavierDuplicates` is that it never returns a longer list than it was passed as a parameter. A property test was written to check this, and this failed. However, upon closer inspection, it immediately became apparent that this was because the `>=` operator had been used instead of `<=` in the test itself. This was amended, and the test rerun and passed.

Another of the properties of `removeHeavierDuplicates` is that no two Edges in the returned list should have the same start and end values.

---------

The next function to implement was `chooseRandomPath`, which should take a random number generator of type `StdGen` and a list of Edges, and should return a list of Edges containing a subset of the initial list. For generators with different seed values, different selections of edges should be generated. 

Writing tests for this function proved to be more complicated. One initial idea was to simply call the function twice with generators which have seeds which are guaranteed to be different, and test if the outputs differ. The problem with this is that the outputs may well be the same for different seeds, especially with shorter lists of Edges (and must be the same if the list is empty).  

A simpler property to test is that `chooseRandomPath` does not return a greater number of edges than it is given. A test was written to test this, and the function was made to pass this. As this requires a `StdGen` as a parameter, `StdGen` also needed an instance declaration of `Arbitrary`. This was done in the same way as it was for `Edge`. However, this test could be passed by just making the function return its input. 

One way to guarantee the outputs are different is to provide two `StdGen`s which are known to return different values when they are run. To do this, a new type `StdGenDiffPair`, isomorphic with (`StdGen`, `StdGen`), was declared; the `suchThat` predicate was used in the `Arbitrary` instance declaration of this new type to ensure that the first `Bool` values generated by each of the `StdGen`s are different. This was done by using the `next` function to look ahead. However, if the list is empty, the return values must still be equal, so a generator had to be defined to generate a list which is guaranteed not to be empty. As such, `EdgeListNonEmpty` was declared and set up in much the same way as `StdGenDiffPair`. These types could then be used by a new property test `prop_chooseRandomPathReturnsDifferentPathsForDifferentRngs`, which tests that so long as the `StdGen`s return different values, and the list of edges is not empty, the `chooseRandomPaths` function returns different paths. This new property test failed on running, so the function was modified so that this would pass.

As the returned list of edges represents a path, a type synonym `Path = [Edge]` was added at this point, and used in place of `[Edge]` as the return value of `chooseRandomPath`. After this change, the tests were all re-run.


--------

In order to create a list of candidate paths, a function had to be created to return a list of random paths, given a `StdGen`, a list of edges, and an `Int` representing the number of paths to be created. The returned list must have a length the same as the number of paths to be created, so this made a logical first property test. In the case that the number of paths to be created is zero or less, an empty list should be returned. This test was created, failed, and the function was implemented to pass this test by returning a list of paths of the correct length, but simply using the full list of edges as each path, instead of a random subset of these. This test initially used guards to check if `num < 0`, and to return `True` if this is the case. The problem with this is that the test itself became too large, so this was replaced with another `newtype` and `instance` declaration, this time for `IntAtLeastOne`, which allows for the generation of ints which are guaranteed to be at least one.

The sets of paths should differ for generators which are guaranteed to give different values, so a test `prop_chooseRandomPathsDiffersWithG` was created to test this. The previously created `StdGenDiffPair` was used again here, as was `EdgeListNonEmpty`. Test failed, code changed to use `chooseRandomPath` function, 

The paths within the set should not all be identical, so another test was written to check that at least one of the paths is different from the first in the list. This failed, and the function was modified so that the paths differ. A problem encountered, however, was that the arbitrary `StdGen`s used in by the tests may happen to return the same value for the first two random numbers. If this happens, and the number of paths to generate is only two, then the two paths will be the same if the number of edges is only one. The reason for this is that there is only one edge, and this either is or is not in a path, and if the first two values returned by the generator are the same then whether this is present will be the same in the first two paths. In addition, if only one path is generated, there cannot be variation between paths. To resolve this, the test was improved by adding one to the `IntAtLeastOne`, therefore making it at least two, and another `newtype` & `instance` were added to create a new generator which creates `StdGen`s which are guaranteed to return different boolean values the first two times they are used.   

The test generators at this point had become to take up quite a lot of the tests file, so at this point they were refactored out to a separate file.


--------


The next step was to create a function to return the best paths from a set. This should take a list of paths and the number to return. The length of the returned list should be the lesser of either the length of the original list or the number to return, so a test was written to test this.

The next property to test was whether the paths returned are the highest scorers. In order to write this test and implement the function itself, a scoring function needed to be implemented.

The `scorePath` function returns an `Int` representing the score of the path. The scoring is to be done as follows:


--------

At this point I defined a `runAllTests` function to run the tests all at once, and modified the `Main.hs` file to run this function, as running tests through the REPL had become tedious.



---------





\pagebreak

# Reflection on using Test-Driven Development, Functional Programming, and testing tools


I have found Functional Programming to produce very clean and concise code, particularly when combined with Test-Driven Development. A particular advantage of Haskell is that the type system makes it very clear what a function can affect. This is because the type signature indicates whether a function is pure, and if it is then it will not mutate the values passed to it. This is an advantage over languages like C++, where many pointers may refer to the same object, and this object may be changed (possibly inadvertantly) from many places in the program. This makes the behaviour of functions harder to predict, as it is harder to tell what side effects they have.

A strong disadvantage I found with Functional Programming was the initial difficulty in not just the slightly unusual syntax of Haskell (as compared to C-like languages), but also the challenge of learning to "Think Functionally". The difference in syntax has a silver lining however, in that I found it to removed the temptation to write C/Java -like code in Haskell. This is an advantage that Haskell has over Scala, as Scala allows for many things to be done in the "FP way" or the "OOP way". This can result in functions which should be pure being written impurely. However, Scala and other hybrid languages are less of a jump to move to from other paradighms, and Scala interoperates seamlessly with Java. 

I enjoy working with functional languages, and find Functional Programming an interesting way to work. As such I do intend to use it in future personal projects. Furthermore, the impression left by the the median salaries listed at itjobswatch.co.uk, a selection of which are shown in the table below, strongly inclines me towards working with functional (or at least functional-heavy hybrid) languages professionally. Haskell has the highest median salary, and Scala, a functional-heavy hybrid, also does well. It is worth also noting that functional-style code is possible in other languages in the list - Python includes lambdas, as do the more recent versions of C++ and Java.

|Language|Median Salary|
|--------|-------|
|Haskell| £85,000|
|Scala| £72,500|
|Java| £65,000|
|Python| £62,500|
|C++| £55,000|
|C| £52,500|
|JavaScript| £52,500|

**Source: itjobswatch.co.uk**

This is a one dimensional view, and does not take into account cost of living in areas where these jobs tend to be, ease with which the jobs can be found, or the other skills developers are likely to have (e.g. Python Software Engineers who happen to be proficient in Machine Learning techniques).

The higher price point of functional programmers would also leave me disinclined to choose such a language to build a product in if I were running a software company, unless there was an overwhelming advantage to choosing such a language. However, I would still encourage the usage of functional-style code within hybrid languages. As well as this, even if a language's type system does not strongly encourage writing functions without side effects, it is still possible to write functions without side effects in languages other than Haskell (Martin, R.C. (2010), a book mainly targeted at Java developers, states as a rule that functions should "Have No Side Effects"). Properly considering what is to be written before starting writing it ("Measure twice cut once") is another lesson from Functional Programming which can be transferred to other Languages.

## TDD

### +



### -

### →


## TDD

### +

### -

### →

## What went well

Being forced to thoroughly consider what each function should actually do 

- Test names naturally lend themselves to good git commit messages

### reasons

## What could have gone better

### Reasons

## What should be done in the future

In the future

\pagebreak

# Libraries Used


 Test.QuickCheck
 Test.HUnit
 System.Random
 Data.Sort


# References

Beck, K., 2003. Test-driven development: by example. Addison-Wesley Professional.

George, B. and Williams, L., 2004. A structured experiment of test-driven development. Information and software Technology, 46(5), pp.337-342.

IT Jobs Watch. (n.d.). IT Jobs Watch | Tracking the IT Job Market. [online] Available at: https://www.itjobswatch.co.uk [Accessed 21 May 2020].

Martin, R.C. (2010). Clean code a handbook of agile software craftmanship. Upper Saddle River [Etc.] Prentice Hall.

Maximilien, E.M. and Williams, L., 2003, May. Assessing test-driven development at IBM. In 25th International Conference on Software Engineering, 2003. Proceedings. (pp. 564-569). IEEE.



